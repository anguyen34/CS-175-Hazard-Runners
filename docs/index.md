---
layout: default
title:  Home
---

## Source code: 

[https://github.com/anguyen34/Tron-Researchers-CS175](https://github.com/anguyen34/Tron-Researchers-CS175)

## ColosseumRL: 

[https://colosseumrl.igb.uci.edu/](https://colosseumrl.igb.uci.edu/)

## Project Summary:

We study the effects of changing various parameters across five different functional approximators for Q-Learning in the ColosseumRL Tron game. Our goal is to see which parameters are the most influential in determining the performance of our policies in Tron. A secondary goal is to determine a fine tuned set of parameters for each policy using data from our primary goal, which plays Tron optimally against other agents using the same policy. Once we have determined the optimal parameters for each policy we intend to have different policies play against each other to determine which policy is the most effective at playing Tron. The five approximators we use are a neural network, a random forest, an ensemble, a linear combination of features, and a Monte Carlo search tree.

## Reports:

- [Proposal](proposal.html) 
- [Updated Proposal](proposalUpdate.html)
- [Status](status.html)
- [Final](final.html)
